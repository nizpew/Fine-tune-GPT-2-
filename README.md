
## ğŸ‡§ğŸ‡· Fine-tune-GPT-2 (VersÃ£o em PortuguÃªs)

> *Este projeto utiliza **Flask** â€” um framework web leve em Python, comum para APIs e microsserviÃ§os â€” para criar sua prÃ³pria API local, realizando chamadas e retornando as respostas do modelo treinado localmente com base no prompt fornecido.*

<details>
<summary><strong>Clique para expandir a versÃ£o em portuguÃªs</strong></summary>

---

### ğŸ§  Gerador Inteligente de Tarefas (Modelo GPT-2 Ajustado)

Uma versÃ£o ajustada do modelo de linguagem GPT-2, projetada para compreender comandos em linguagem natural e gerar descriÃ§Ãµes estruturadas de tarefas â€” com nomes de tarefas e horÃ¡rios apropriados â€” ideal para ferramentas de produtividade, assistentes virtuais e lembretes inteligentes.

---

### ğŸ› ï¸ Como usar

```bash
# Instale se for a primeira vez
python3 -m venv ai-backend-env
pip install flask transformers torch
source ai-backend-env/bin/activate

# Caso jÃ¡ tenha instalado anteriormente, apenas ative:
source ai-backend-env/bin/activate

# FaÃ§a uma chamada para a API local:
curl -X POST http://localhost:5000/generate \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Crie uma tarefa para ir ao dentista"}'
```

Resposta esperada:

```json
"response": "Tarefa de consulta no dentista adicionada.\n[TASK: Consulta no dentista | TIME: 10:00]"
```

---

### ğŸ“Œ DescriÃ§Ã£o do Projeto

Este projeto apresenta uma implementaÃ§Ã£o prÃ¡tica de ajuste fino do GPT-2 para um assistente de gerenciamento de tarefas em linguagem natural. Dado um prompt do usuÃ¡rio (ex.: *"me lembre de ligar para o mÃ©dico"*), o modelo retorna uma resposta estruturada como:

```
Assistente:
Lembrete criado para ligar para o mÃ©dico.
[TASK: Ligar para o mÃ©dico | TIME: 10:30]
```

---

### âœ… Funcionalidades Principais

* ğŸ’¬ Entende comandos em linguagem natural
* ğŸ“‹ Gera tarefas estruturadas no formato `[TASK: ... | TIME: ...]`
* â° Aprende alocar horÃ¡rios coerentes com o contexto
* ğŸ¤– Modelo ajustado com dataset customizado
* ğŸ§ª Pronto para uso com `transformers.pipeline`

---

### ğŸ“‚ Conjunto de Dados

```json
{
  "text": "UsuÃ¡rio: me lembre de regar as plantas\nAssistente:\nLembrete criado para regar as plantas.\n[TASK: Regar plantas | TIME: 09:00]"
}
```

---

### ğŸ› ï¸ Tecnologias Utilizadas

* Python 3.x
* ğŸ¤— Transformers (`GPT2LMHeadModel`)
* Hugging Face Datasets
* PyTorch
* Google Colab + aceleraÃ§Ã£o com CUDA

---

### ğŸš€ Como Funciona

1. Carrega e tokeniza o dataset customizado
2. Ajusta o GPT-2 com o `Trainer` da Hugging Face
3. Exporta e usa localmente ou em uma pipeline
4. Entrada: `"UsuÃ¡rio: terminar o relatÃ³rio"`
5. SaÃ­da:

```
Assistente:
Tarefa de relatÃ³rio adicionada.
[TASK: Terminar relatÃ³rio | TIME: 16:00]
```

---

### ğŸ§  Proposta de Valor

Demonstra a capacidade de personalizar LLMs para tarefas reais, transformando modelos genÃ©ricos em assistentes de domÃ­nio especÃ­fico. Ideal para:

* Ferramentas de produtividade/calendÃ¡rio inteligente
* Backends de assistentes virtuais
* Interfaces conversacionais
* Aplicativos de gerenciamento de tempo

---

### ğŸ“ˆ Resultados

* Compreende intenÃ§Ãµes do usuÃ¡rio
* Gera saÃ­das claras e bem estruturadas
* Sugere horÃ¡rios realistas com base no tipo de tarefa

---

### ğŸ“¥ InferÃªncia Local

```python
from transformers import pipeline

generator = pipeline("text-generation", model="./gpt2-tasker", tokenizer="./gpt2-tasker")

prompt = "UsuÃ¡rio: me lembre de ligar para o mÃ©dico\nAssistente:\n"
output = generator(prompt, max_length=100, do_sample=True)
print(output[0]["generated_text"])
```

---

### ğŸ™‹ Sobre Mim

Este projeto faz parte da minha exploraÃ§Ã£o prÃ¡tica em:

* CustomizaÃ§Ã£o de modelos LLM
* Engenharia de prompts
* Curadoria de dados para tarefas reais

Se procura alguÃ©m que una **proeficiÃªncia em deep learning** com **visÃ£o de produto**, entre em contato!

</details>

---

## ğŸ‡ºğŸ‡¸ Fine-tune-GPT-2 (English Version)

> *This project uses **Flask** â€” a lightweight Python web framework, commonly used for APIs & microservices â€” to create a local API that makes calls and retrieves responses from a locally trained model based on the provided prompt.*

<details>
<summary><strong>Click to expand the English version</strong></summary>

---

### ğŸ§  Smart Task Generator (Fine-Tuned GPT-2 Model)

A fine-tuned version of the GPT-2 language model designed to understand natural language prompts and generate structured task descriptions â€” complete with task names and appropriate execution times â€” ideal for productivity tools, virtual assistants, and smart reminders.

---

### ğŸ› ï¸ Using

```bash
# Install if first time
python3 -m venv ai-backend-env
pip install flask transformers torch
source ai-backend-env/bin/activate

# If not, just activate:
source ai-backend-env/bin/activate

# Call local API
curl -X POST http://localhost:5000/generate \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Create a task for me to go to the dentist"}'
```

Expected response:

```json
"response": "Dentist appointment task added.\n[TASK: Dentist appointment | TIME: 10:00]"
```

---

### ğŸ“Œ Project Description

This project showcases a hands-on implementation of **fine-tuning GPT-2** for a **natural language task management assistant**. Given a user prompt (e.g., *"remind me to call the doctor"*), the model returns a structured response such as:

```
Assistant:
Reminder set to call the doctor.
[TASK: Call doctor | TIME: 10:30]
```

---

### âœ… Key Features

* ğŸ’¬ Understands natural language task commands
* ğŸ“‹ Generates structured tasks with `[TASK: ... | TIME: ...]` format
* â° Learns appropriate timing (e.g., workouts in the morning, meetings in the afternoon)
* ğŸ¤– Fully fine-tuned on **custom curated dataset**
* ğŸ§ª Ready-to-use with `transformers` pipeline for inference

---

### ğŸ“‚ Dataset

```json
{
  "text": "User: remind me to water the plants\nAssistant:\nReminder set to water the plants.\n[TASK: Water plants | TIME: 09:00]"
}
```

---

### ğŸ› ï¸ Tech Stack

* Python 3.x
* ğŸ¤— Transformers (`GPT2LMHeadModel`)
* HuggingFace Datasets
* PyTorch
* Google Colab + CUDA acceleration

---

### ğŸš€ How It Works

1. Load and tokenize the custom dataset
2. Fine-tune GPT-2 using `Trainer` from Hugging Face
3. Export and use the model locally or in a pipeline
4. Input: `"User: create a task to finish the report"`
5. Output:

```
Assistant:
Report task added.
[TASK: Finish report | TIME: 16:00]
```

---

### ğŸ§  Value Proposition

This project demonstrates the ability to **customize LLMs for real-world tasks**, transforming general-purpose language models into **domain-specific assistants**. Ideal for:

* Smart calendar or productivity tools
* Virtual assistant backends
* Conversational UI systems
* User-centric time management apps

---

### ğŸ“ˆ Results

* Understands user intent
* Produces clear and clean outputs
* Generates meaningful time allocations with task descriptions

---

### ğŸ“¥ Installation & Inference

```python
from transformers import pipeline

generator = pipeline("text-generation", model="./gpt2-tasker", tokenizer="./gpt2-tasker")

prompt = "User: remind me to call the doctor\nAssistant:\n"
output = generator(prompt, max_length=100, do_sample=True)
print(output[0]["generated_text"])
```

---

### ğŸ™‹ About Me

This project is part of my practical exploration into:

* LLM fine-tuning
* Prompt engineering
* Data curation for real-world NLP applications

If you're looking for someone who blends **deep learning proficiency** with **product vision**, feel free to reach out!

</details>

